@article{Ang2007,
author = {Ang, Andrew and Bekaert, Geert and Wei, Min},
doi = {10.3386/w11538},
file = {:Users/miyoshi/Documents/Papers/Ang, Bekaert, Wei - 2007 - Do Macro Variables, Asset Markets or Surveys Forecast Inflation Better.pdf:pdf},
journal = {Journal of Monetary Economics},
number = {4},
pages = {1163--1212},
title = {{Do Macro Variables, Asset Markets or Surveys Forecast Inflation Better?}},
url = {http://www.nber.org/papers/w11538.pdf},
volume = {54},
year = {2007}
}
@incollection{Armstrong2001,
abstract = {To improve forecasting accuracy, combine forecasts derived from methods that differ substantially and draw from different sources of information. When feasible, use five or more methods. Use formal procedures to combine forecasts: An equal-weights rule offers a reasonable starting point, and a trimmed mean is desirable if you combine forecasts resulting from five or more methods. Use different weights if you have good domain knowledge or information on which method should be most accurate. Combining forecasts is especially useful when you are uncertain about the situation, uncertain about which method is most accurate, and when you want to avoid large errors. Compared with errors of the typical individual forecast, combining reduces errors. In 30 empirical comparisons, the reduction in ex ante errors for equally weighted combined forecasts averaged about 12.5{\%} and ranged from 3 to 24 percent. Under ideal conditions, combined forecasts were sometimes more accurate than their most accurate components.},
author = {Armstrong, J. Scott},
booktitle = {Principles of Forecasting},
doi = {10.1007/978-0-306-47630-3_19},
file = {:Users/miyoshi/Documents/Papers/Armstrong - 2001 - Combining Forecasts.pdf:pdf},
isbn = {978-0-7923-7401-5},
issn = {0884-8289},
keywords = {assume that you want,budget to doing one,but you have a,consensus,discussion,doing a thorough,domain knowledge,earnings forecasts,equal weights,for example,group,jones,limited budget,rule-based forecasting,smith murdered mr,task well,to determine whether mr,to devote the complete,uncertainty,would it be better},
pages = {417--439},
publisher = {Springer},
title = {{Combining Forecasts}},
url = {http://link.springer.com/chapter/10.1007/978-0-306-47630-3{\_}19 http://link.springer.com/10.1007/978-0-306-47630-3{\_}19},
year = {2001}
}
@article{Choudhary2012,
author = {Choudhary, M. Ali and Haider, Adnan},
doi = {10.1080/00036846.2011.566190},
file = {:Users/miyoshi/Documents/Papers/Choudhary, Haider - 2012 - Neural network models for inflation forecasting an appraisal.pdf:pdf},
issn = {0003-6846},
journal = {Applied Economics},
month = {jul},
number = {20},
pages = {2631--2635},
title = {{Neural network models for inflation forecasting: an appraisal}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00036846.2011.566190},
volume = {44},
year = {2012}
}
@incollection{Graves2012,
author = {Graves, Alex},
booktitle = {Supervised Sequence Labelling with Recurrent Neural},
chapter = {4},
doi = {10.1007/978-3-642-24797-2},
file = {:Users/miyoshi/Documents/Papers/Graves - 2012 - Long Short-Term Memory.pdf:pdf},
pages = {31--38},
publisher = {Springer},
title = {{Long Short-Term Memory}},
url = {http://www.springer.com/jp/book/9783642247965},
year = {2012}
}
@book{Howe2008,
author = {Howe, Jeff},
publisher = {Crown Publishing Group},
title = {{Crowdsourcing}},
year = {2008}
}
@article{Krogh1995,
abstract = {Learning of continuous valued functions using neural network ensembles (committees) can give improved accuracy, reliable estimation of the generalization error, and active learning. The ambiguity is defined as the variation of the output of ensemble members averaged over unlabeled data, so it quantifies the disagreement among the networks. It is discussed how to use the ambiguity in combination with cross-validation to give a reliable estimate of the ensemble generalization error, and how this type of ensemble cross-validation can sometimes improve performance. It is shown how to estimate the optimal weights of the ensemble members using unlabeled data. By a generalization of query by committee, it is finally shown how the ambiguity can be used to select new training data to be labeled in an active learning scheme. 1 INTRODUCTION It is well known that a combination of many different predictors can improve predictions. In the neural networks community "ensembles" of neural networks h...},
author = {Krogh, Anders and Vedelsby, Jesper},
doi = {10.1.1.37.8876},
file = {:Users/miyoshi/Documents/Papers/Krogh, Vedelsby - 1995 - Neural Network Ensembles, Cross Validation, and Active Learning.pdf:pdf},
isbn = {0262201046},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {231--238},
title = {{Neural Network Ensembles, Cross Validation, and Active Learning}},
volume = {7},
year = {1995}
}
@article{Lamberson2012,
author = {Lamberson, P. J. and Page, Scott E.},
doi = {10.1287/mnsc.1110.1441},
file = {:Users/miyoshi/Documents/Papers/Lamberson, Page - 2012 - Optimal Forecasting Groups(2).pdf:pdf},
issn = {0025-1909},
journal = {Management Science},
month = {apr},
number = {4},
pages = {805--810},
title = {{Optimal Forecasting Groups}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.1110.1441},
volume = {58},
year = {2012}
}
@incollection{Mitchell1997,
author = {Michell, Tom M.},
booktitle = {Machine Learning},
chapter = {4},
pages = {191--193},
publisher = {McGraw-Hill},
title = {{Artificial Neural Networks}},
year = {1997}
}
@article{Moshiri2000,
abstract = {Artificial neural network modeling has recently attracted much attention as a new technique for estimation and forecasting in economics and finance. The chief advantages of this new approach are that such models can usually find a solution for very complex problems, and that they are free from the assumption of linearity that is often adopted to make the traditional methods tractable. The performance of Back Propagation Artificial Neural Network (BPN) models is compared with the traditional econometric approaches to forecasting the inflation rate. Of the traditional econometric models, a structural reduced-form model, an ARIMA model, a vector autoregressive model, and a Bayesian vector autoregression model are used. Each econometric model is compared with a hybrid BPN model which uses the same set of variables. Dynamic forecasts are compared for three different horizons: one, three and twelve months ahead. Root mean squared errors and mean absolute errors are used to compare quality of forecasts. The results show the hybrid BPN models are able to forecast as well as all the traditional econometric methods, and to outperform them in some cases.},
author = {Moshiri, Saeed and Cameron, Norman},
doi = {10.1002/(SICI)1099-131X(200004)19:3<201::AID-FOR753>3.0.CO;2-4},
file = {:Users/miyoshi/Documents/Papers/Moshiri, Cameron - 2000 - Neural network versus econometric models in forecasting inflation.pdf:pdf},
isbn = {02776693},
issn = {0277-6693},
journal = {Journal of Forecasting},
keywords = {arti,ation,cial neural network models,forecasting,structural models,time series models},
month = {apr},
number = {3},
pages = {201--217},
title = {{Neural network versus econometric models in forecasting inflation}},
url = {http://doi.wiley.com/10.1002/(SICI)1099-131X(200004)19:3{\%}3C201::AID-FOR753{\%}3E3.0.CO;2-4},
volume = {19},
year = {2000}
}
@article{Nakamura2005,
abstract = {This paper evaluates the usefulness of neural networks for inflation forecasting. In a pseudo-out-of-sample forecasting experiment using recent U.S. data, neural networks outperform univariate autoregressive models on average for short horizons of one and two quarters. A simple specification of the neural network model and specialized estimation procedures from the neural networks literature appear to play significant roles in the success of the neural network model. ?? 2004 Elsevier B.V. All rights reserved.},
author = {Nakamura, Emi},
doi = {10.1016/j.econlet.2004.09.003},
file = {:Users/miyoshi/Documents/Papers/Nakamura - 2005 - Inflation forecasting using a neural network.pdf:pdf},
issn = {01651765},
journal = {Economics Letters},
keywords = {Forecasting,Model selection},
month = {mar},
number = {3},
pages = {373--378},
title = {{Inflation forecasting using a neural network}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165176504003088},
volume = {86},
year = {2005}
}
@book{Page2008,
author = {Page, Scott E},
isbn = {9780691138541},
publisher = {Princeton University Press},
title = {{The Defference}},
url = {https://books.google.co.jp/books?id=hJRu4O8q1xwC},
year = {2008}
}
@article{Rothe2016,
author = {Rothe, Rasmus and Timofte, Radu and {Van Gool}, Luc},
doi = {10.1007/s11263-016-0940-3},
file = {:Users/miyoshi/Documents/Papers/Rothe, Timofte, Van Gool - 2016 - Deep expectation of real and apparent age from a single image without facial landmarks.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision (IJCV)},
month = {jul},
title = {{Deep expectation of real and apparent age from a single image without facial landmarks}},
url = {http://link.springer.com/10.1007/s11263-016-0940-3 https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/},
year = {2016}
}
@book{Surowiecki2004,
author = {Surowiecki, James},
publisher = {Doubleday},
title = {{The Wisdom of Crowds}},
year = {2004}
}
@inproceedings{Ueda1996,
abstract = {It has been empirically shown that a better estimate with less$\backslash$ngeneralization error can be obtained by averaging outputs of multiple$\backslash$nestimators. This paper presents an analytical result for the$\backslash$ngeneralization error of ensemble estimators. First, we derive a general$\backslash$nexpression of the ensemble generalization error by using factors of$\backslash$ninterest (bias, variance, covariance, and noise variance) and show how$\backslash$nthe generalization error is affected by each of them. Some special cases$\backslash$nare then investigated. The result of a simulation is shown to verify our$\backslash$nanalytical result. A practically important problem of the ensemble$\backslash$napproach, ensemble dilemma, is also discussed},
author = {Ueda, N. and Nakano, R.},
booktitle = {Proceedings of International Conference on Neural Networks (ICNN)},
doi = {10.1109/ICNN.1996.548872},
file = {:Users/miyoshi/Documents/Papers/Ueda, Nakano - 1996 - Generalization error of ensemble estimators.pdf:pdf},
isbn = {0-7803-3210-5},
pages = {90--95},
title = {{Generalization error of ensemble estimators}},
url = {http://ieeexplore.ieee.org/document/548872/},
volume = {1},
year = {1996}
}
@incollection{Zhou2012,
author = {Zhou, Zhi-Hua},
booktitle = {Ensemble Methods},
chapter = {4},
file = {:Users/miyoshi/Documents/Papers/Zhou - 2012 - Combination Method.pdf:pdf},
isbn = {1439830053},
issn = {9781439830055},
pages = {67--98},
publisher = {CRC Press},
title = {{Combination Method}},
url = {https://books.google.co.jp/books?id=MFzRBQAAQBAJ},
year = {2012}
}
@book{岡谷2015,
author = {{岡谷 貴之}},
booktitle = {深層学習},
pages = {111--130},
publisher = {講談社},
title = {深層学習},
year = {2015}
}
@book{沖本2010,
author = {{沖本 竜義}},
isbn = {978-4254127928},
publisher = {朝倉書店},
title = {経済・ファイナンスデータの計量時系列分析},
year = {2010}
}
